---
title: "2.Gene_expresion"
author: "Fay"
date: '2022-05-27'
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries:
```{r libraries}
#install.packages("optimx", version = "2021-10.12") # this package is required for 
#the parasite load package to work
library(tidyverse)
library(tidyr)
library(dplyr)
library(cowplot)
library(randomForest)
library(ggplot2)
library(caret)
library(VIM) # visualizing missing data
library(mice) # imputing missing data without predictors
library(ggpubr)
library(optimx)
```


## Import the data:

```{r import}
# Here we import the cleaned data set from the previous script derived from the 
# data set challenge infections 
g <- read.csv("https://raw.githubusercontent.com/fayweb/Eimeria_mouse_immunity/main/output_data/gene_expression/data_products/clean_gene_expression.csv")


# vectors for selecting gene columns
Genes <- c("IFNy", "CXCR3_bio", "IL.6", "IL.10", "IL.13", "IL.10", "IL.13", "IL1RN", 
           "CASP1", "CXCL9", "IDO1", "IRGM1", "MPO", "MUC2", "MUC5AC", "MYD88", 
           "NCR1", "PRF1", "RETNLB", "SOCS1", "TICAM1", "TNF")

```



## Data cleaning

```{r cleaning}
# we need to change the  in challenge infections to a factor
g$Parasite_challenge <- as.factor(g$Parasite_challenge)
g$Eim_MC <- as.factor(g$Eim_MC)

# Here I create a new column, where we get the actual infection status
# According to the melting curve for eimeria 
g <- g %>%
  dplyr::mutate(current_infection = case_when(
    Parasite_challenge == "E_ferrisi" & Eim_MC == "TRUE" ~ "E_ferrisi",
    Parasite_challenge == "E_ferrisi" & Eim_MC == "FALSE" ~ "uninfected",
    Parasite_challenge == "E_falciformis" & Eim_MC == "TRUE" ~ "E_falciformis",
    Parasite_challenge == "E_falciformis" & Eim_MC == "FALSE" ~ "uninfected",
    Parasite_challenge == "uninfected" & Eim_MC == "TRUE" ~ "infected_eimeria",
    Parasite_challenge == "uninfected" & Eim_MC == "FALSE" ~ "uninfected",
    TRUE ~ ""
  ))


# how to impute delta? Replacing with 0 the ones with negative melting curve
# open for other solutions!
g <- g %>%
  dplyr::mutate(Intensity = case_when(
    Eim_MC == "TRUE" ~ delta,
    Eim_MC == "FALSE" ~ 0))

# create variable maximum weight loss instead of maximum relative weight loss
g <- g %>% dplyr::mutate(max_WL = 100 - max_WL)


```





## Imputing missing data + cleaning
```{r imputing}
#Start by selecting only the genes and the maximum weight loss for each mouse
# Apparently the relative end weight doesn't work so well for predictions

g.1 <- g %>%
  dplyr::select(c(max_WL, all_of(Genes)))

# to get reproducible results we use a seed
set.seed(42)

# We want the maximum weight loss to be predicted by the data ina ll of the other columns

# iter = how many random forests are needed, in theory 6 are enough
g.imputed <- rfImpute(max_WL ~ ., data = g.1, iter = 6)

g.imputed <- g.imputed %>% dplyr::select(-max_WL)

g_minus <- g %>% 
  dplyr::select(-all_of(Genes)) 

#full data set containing the imputed gene expression data
g.imputed <- cbind(g_minus, g.imputed)



```



How many mice are in the infection planning?
```{r infection_plan}
g.imputed %>% 
  filter(infection == "challenge") %>%
  group_by(Parasite_challenge) %>%
  summarize(length(EH_ID))
  
```
How many mice are indeed infected?

```{r infected}
g.imputed %>% 
  filter(infection == "challenge") %>%
  group_by(current_infection) %>%
  summarize(length(EH_ID))
  
```
I guess mice got mixed up here?

## Splitting data into training and testing sets 
Splitting between training and testing:
- Assess model performance on unseen data
- Avoid over-fitting 



```{r }
g.imputed_full <- g.imputed

#select the relevant columns:
g.imputed <- g.imputed %>%
  dplyr::select(c(max_WL, all_of(Genes))) %>%
  dplyr::select(- CXCR3_bio)

# split data into training and test

set.seed(123) # this will help us reproduce this random assignment

# in this way we can pick the random numbers

training.samples <- g.imputed$max_WL%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return

train.data <- g.imputed[training.samples, ] #include all the randomly selected rows
test.data <- g.imputed[-training.samples, ] 


```



## Building the model

```{r }
#train the model
model <- randomForest(max_WL ~., data = train.data, proximity = TRUE,
                      ntree = 1000) # number of trees
                      

print(model)
```

Plotting the model will illustrate the error rate as we average across more trees and shows that our error rate stabalizes with around 200 trees.



```{r}
plot(model)
```
The plotted error rate above is based on the OOB sample error and can be accessed directly at m1$mse. Thus, we can find which number of trees providing the lowest error rate, which is 257 trees providing an weight error of 5.024738.

```{r}
# number of trees with lowest MSE
which.min(model$mse)
## [1] 257

# RMSE of this optimal random forest
sqrt(model$mse[which.min(model$mse)])
## [1] 5.024738
```

### https://uc-r.github.io/s
RandomForest also allows us to use a validation set to measure predictive accuracy if we did not want to use the OOB samples. 



Tutorial: https://hackernoon.com/random-forest-regression-in-r-code-and-interpretation
Random forest regression in R provides two outputs: decrease in mean square error (MSE) and node purity. Prediction error described as MSE is based on permuting out-of-bag sections of the data per individual tree and predictor, and the errors are then averaged. In the regression context, Node purity is the total decrease in residual sum of squares when splitting on a variable averaged over all trees (i.e. how well a predictor decreases variance). MSE is a more reliable measure of variable importance. If the two importance metrics show different results, listen to MSE. If all of your predictors are numerical, then it shouldn’t be too much of an issue


Mean Decrease Gini (IncNodePurity) - This is a measure of variable importance based on the Gini impurity index used for the calculating the splits in trees.

Improving Your Model
Your model depends on the quality of your dataset and the type of Machine Learning algorithm used. Therefore, to improve the accuracy of your model, you should:

Check what attributes affect our model the most and what variables to leave out in future analysis
Find out what other attributes affect a person's wage; we can use as predictors in future analysis
Tweak the algorithm (e.g. change the ntree value)
Use a different machine learning algorithm
If any of these reduces the RMSE significantly, you have succeeded in improving your model!

```{r include = FALSE, message = FALSE, echo = FALSE}
### Visualize variable importance ----------------------------------------------

#Call importance() function on the model model to check how the attributes used as predictors affect our model
importance(model)

model$mse
## S3 method for class 'randomForest'
plot(model, type = "l", main=deparse(substitute(x)))

varImpPlot(model)

# Get variable importance from the model fit
ImpData <- as.data.frame(importance(model))
ImpData$Var.Names <- row.names(ImpData)

#ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
 # geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
  #geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
  #theme_light() +
  #coord_flip() +
  #theme(
   ## legend.position="bottom",
    #panel.grid.major.y = element_blank(),
    #panel.border = element_blank(),
    #axis.ticks.y = element_blank()
  #)
```



## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions <- predict(model, test.data)

# assign test.data to a new object, so that we can make changes
result <- test.data

#add the new variable of predictions to the result object
result <- cbind(result, predictions)

#add the results to a data frame containing test data and the prediction
result <- cbind(g[row.names(result), ], predictions)

```




## Visualizations



```{r }
# trying to find a way to represent the delta ct for the negative ones
# please find a better way to do this
result <- result %>% 
    dplyr::mutate(delta2 = case_when(
       current_infection == "uninfected" ~ -10,
       TRUE ~ delta
    ))

cor(result$predictions, result$max_WL)

result   %>%
  ggplot() +
  geom_point(aes(x = predictions, y = max_WL, color = current_infection, size = delta2)) +
  labs(x = "Predictions: Maximum weight loss", y = "Observed: Maximum weight loss") +
    theme_bw()

cor.test(result$predictions, result$max_WL, method = "spearman")
  
```

## Predicting eimeria species according to gene expression
```{r}
g$Parasite_challenge <- as.factor(g$Parasite_challenge)

#now select the genes and the actual infection of the mice in the new mutate column
#infection
g.2 <- g %>% 
    dplyr::select(c(Parasite_challenge, delta, all_of(Genes)))

# to get reproducible results we use a seed
set.seed(42)
# We want the current infection to be predicted by the data ina ll of the other columns
# iter = how many random forests are needed, in theory 6 are enough


#now we can impute our data
g.imputed_parasite <- rfImpute(Parasite_challenge ~ ., data = g.2, iter = 6)

g.imputed_parasite <- g.imputed_parasite %>% dplyr::select(- Parasite_challenge)

g_minus <- g %>% dplyr::select(-c((all_of(Genes)), delta))

#full data set containing the imputed gene expression data
g.imputed_parasite <- cbind(g_minus, g.imputed_parasite)


```

## Now split the data again into training and testing
```{r }

g.imputed_parasite$Parasite_challenge <- as.factor(g.imputed_parasite$Parasite_challenge)

#select the relevant columns:
g.imputed_parasite <- g.imputed_parasite %>%
  dplyr::select(c(Parasite_challenge, all_of(Genes)))

g.imputed_parasite <- g.imputed_parasite %>%
    dplyr::select(-CXCR3_bio)
# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_parasite <- g.imputed_parasite$Parasite_challenge%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_parasite <- g.imputed_parasite[training.samples, ] #include all the randomly selected rows
test.data_parasite <- g.imputed_parasite[-training.samples, ] 


```

## Building the model

```{r }
#train the model
model_Parasite <- randomForest(Parasite_challenge ~., data = train.data_parasite, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_Parasite)
```
OOB = 46.43, this means that only 53 % of our predictions are accurate



```{r}
plot(model_Parasite)
```

## Test the model


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_parasite <- predict(model_Parasite, test.data_parasite)
# assign test.data to a new object, so that we can make changes
result_parasite <- test.data_parasite
#add the new variable of predictions to the result object
result_parasite <- cbind(result_parasite, predictions_parasite)
#add the results to a data frame containing test data and the prediction
result_parasite <- cbind(g[row.names(result_parasite), ], predictions_parasite)
```




## Predicting eimeria species according to gene expression

```{r}
g$Parasite_challenge <- as.factor(g$Parasite_challenge)

#now select the genes and the actual infection of the mice in the new mutate column
#infection
g.2 <- g %>% 
    dplyr::select(c(Parasite_challenge, delta, all_of(Genes)))

# to get reproducible results we use a seed
set.seed(42)
# We want the current infection to be predicted by the data ina ll of the other columns
# iter = how many random forests are needed, in theory 6 are enough


#now we can impute our data
g.imputed_parasite <- rfImpute(Parasite_challenge ~ ., data = g.2, iter = 6)

g.imputed_parasite <- g.imputed_parasite %>% dplyr::select(- Parasite_challenge)

g_minus <- g %>% dplyr::select(-c((all_of(Genes)), delta))

#full data set containing the imputed gene expression data
g.imputed_parasite <- cbind(g_minus, g.imputed_parasite)


```

## Now split the data again into training and testing
```{r splitting_data}

g.imputed_parasite$Parasite_challenge <- as.factor(g.imputed_parasite$Parasite_challenge)

#select the relevant columns:
g.imputed_parasite <- g.imputed_parasite %>%
  dplyr::select(c(Parasite_challenge, Eim_MC, all_of(Genes)))

# to use in the next model
parasite_data <- g.imputed_parasite

g.imputed_parasite <- g.imputed_parasite %>% 
  dplyr::select(-Eim_MC)

# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_parasite <- g.imputed_parasite$Parasite_challenge%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_parasite <- g.imputed_parasite[training.samples, ] #include all the randomly selected rows
test.data_parasite <- g.imputed_parasite[-training.samples, ] 
```

## Building the model

```{r }
#train the model
model_Parasite <- randomForest(Parasite_challenge ~., data = train.data_parasite, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_Parasite)
```
OOB = 46.43, this means that only 53 % of our predictions are accurate



```{r}
plot(model_Parasite)
```

## Test the model


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_parasite <- predict(model_Parasite, test.data_parasite)
# assign test.data to a new object, so that we can make changes
result_parasite <- test.data_parasite
#add the new variable of predictions to the result object
result_parasite <- cbind(result_parasite, predictions_parasite)
#add the results to a data frame containing test data and the prediction
result_parasite <- cbind(g[row.names(result_parasite), ], predictions_parasite)
```




## Visualizations



```{r }

conf_matrix_parasite <- confusionMatrix(result_parasite$predictions_parasite, reference = result_parasite$Parasite_challenge)

print(conf_matrix_parasite)

conf_matrix_parasite$table

plt <- as.data.frame(conf_matrix_parasite$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```


```{r}
train.data_parasite %>% 
  group_by(Parasite_challenge) %>%
  summarize(length(Parasite_challenge))
```

### Repeat the previous model, this time testing for
infected with Eimeria or not. ###

```{r melting-curve - model}

# to use in the next model
parasite_data <- parasite_data %>%
  dplyr::select(-Parasite_challenge)

parasite_data <- parasite_data %>%
    dplyr::select(-CXCR3_bio)


# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_melting <- parasite_data$Eim_MC%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_melting <- parasite_data[training.samples, ] #include all the randomly selected rows
test.data_melting <- parasite_data[-training.samples, ] 
```



## Building the model

```{r }
#train the model
model_melting <- randomForest(Eim_MC ~., data = train.data_melting, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_melting)
```

## Test the model


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_melting <- predict(model_melting, test.data_melting)


# assign test.data to a new object, so that we can make changes
result_melting <- test.data_melting
#add the new variable of predictions to the result object
result_melting <- cbind(result_melting, predictions_melting)
#add the results to a data frame containing test data and the prediction
result_melting <- cbind(g[row.names(result_melting), ], predictions_melting)
```





```{r }

conf_matrix_melting <- confusionMatrix(result_melting$predictions_melting, reference = result_melting$Eim_MC)

print(conf_matrix_melting)

conf_matrix_melting$table

plt <- as.data.frame(conf_matrix_melting$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```

## Field data

## Importing field data


```{r}
Field <- read.csv("https://raw.githubusercontent.com/derele/Mouse_Eimeria_Field/master/data_products/SOTA_Data_Product.csv")

```


## Summary statistics for the field data

```{r summary_stats_field}
Field %>% summarise(length(Mouse_ID))
```
We have 1921 mice in total.



```{r genes}
EqPCR.cols      <- c("delta_ct_cewe_MminusE", "MC.Eimeria", "Ct.Eimeria") #,"Ct.Mus""delta_ct_ilwe_MminusE", )

EimGeno.cols    <- c("n18S_Seq", "COI_Seq", "ORF470_Seq", "eimeriaSpecies")

Gene.Exp.cols   <- c("IFNy",  "CXCR3", "IL.6", #"GBP2", "IL.12", "IRG6",
                     "IL.10", "IL.13", "IL.10", "IL.13", "IL1RN",
                     "CXCR3", "CASP1", "CXCL9", 
                     "IDO1", "IRGM1", "MPO", "MUC2", "MUC5AC", "MYD88", 
                     "NCR1", "PRF1", "RETNLB", "SOCS1", "TICAM1", "TNF")

House.Keeping.cols <- c("GAPDH", "PPIB", "B.actin", "B-actin")
```

```{r}
#which are the numbers of the columns of Field
names <- data.frame(colnames(Field))

f <- Field[ , c(76:78, 80:97)]

#how many nas in each column
sapply(f, function(x) sum(is.na(x)))

#remove rows with only nas
f <- f[rowSums(is.na(f)) != ncol(f), ]

Field <- Field %>% 
  dplyr::select(-c(76:78, 80:97))

#merge the data frame to keep only the selected rows
f <- merge(Field, f, by = "row.names") 

```

## Imputing missing data ###

For the lab data I have used the function rfimpute from the package random forest. 
I can't use the same function for our lab data as the function requires the data 
set to contain predictor variable and response variables. 

Therefore I will be using the package MICE (multivariate Imputation by chained 
Equations) which only requires a data frame of missing observations.

Description: *Multiple imputation using Fully Conditional Specification (FCS)*

implemented by the MICE algorithm as described in Van Buuren and
Groothuis-Oudshoorn (2011) <doi:10.18637/jss.v045.i03>. Each variable has
its own imputation model. Built-in imputation models are provided for
continuous data (predictive mean matching, normal), binary data (logistic
regression), unordered categorical data (polytomous logistic regression)
and ordered categorical data (proportional odds). MICE can also impute
continuous two-level data (normal model, pan, second-level variables).
Passive imputation can be used to maintain consistency between variables.
Various diagnostic plots are available to inspect the quality of the
imputations.

https://www.jstatsoft.org/article/view/v045i03

tutorial: https://www.youtube.com/watch?v=WPiYOS3qK70

https://datascienceplus.com/imputing-missing-data-with-r-mice-package/


https://datascienceplus.com/handling-missing-data-with-mice-package-a-simple-approach/



### Missing data can be classified into three categories:
## 1. Missing completely at random (MCAR)
  
  We can't probably predict that value from any other value in the data. MCAR implies the reason for the missingness of a field is completely random, and that we probably can't predict that value from any other value in the data. 
  
## 2. Missing at Random (MAR)

  Missingess can be explained by other values in other columns, but not from that 
  column.
  
## 3. Missing NOT at random (MNAR)


The basic MICE assumption is that the data is missing at random, and that we can make a guess about its true value by looking at other data samples.



## Let's start by cleaning and checking the missing data points in our field data. 

```{r impute_missing}
library(mice)

f <- f %>% dplyr::select(-"Row.names")


#turn the eimeria species into logical
f$eimeriaSpecies <- as.factor(f$eimeriaSpecies)

field_genes <- f %>% 
  dplyr::select(Gene.Exp.cols)

# check the data for missing values
sapply(field_genes, function(x) sum(is.na(x)))

field_genes %>%
  aggr(col = c('navyblue', 'red'), numbers = TRUE, sortVars = TRUE, labels=names(field_genes), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
       
       
marginplot(field_genes[c(1,2)])

```


## Now let's coninue by ussing the package MICE to impute the data

```{r imputing_mice}

# The frequency distribution of the missing cases per variable can be obtained as:
init <- mice(field_genes, maxit = 0)

# table of amount of variables with the amount of missing values 
table(init$nmis)

# which method is used for imputation? In this case the package mice 
# uses the default method for continuous variable, 
# which is pmm, or predictive mean matching

meth <- init$method


# now impute the immune gene expression for the field and save it as the oject: 
# igf
# m=5 refers to the number of imputed datasets. Five is the default value.
igf <- mice(field_genes, method = meth, m = 5, seed = 500)
summary(igf)

# to check each column with imputed data
## igf$imp$IFNy

#Now we can get back the completed dataset using the complete()
completeField <- complete(igf, 1)

```

Predictive mean matching with \(d = 5\) is the default in mice() for continuous data. The method is robust against misspecification of the imputation model, yet performs as well as theoretically superior methods. In the context of missing covariate data, Marshall, Altman, and Holder (2010) concluded that predictive mean matching “produced the least biased estimates and better model performance measures.” Another simulation study that addressed skewed data concluded that predictive mean matching “may be the preferred approach provided that less than 50% of the cases have missing data and the missing data are not MNAR” (Marshall et al. 2010). Kleinke (2017) found that the method works well across a wide variety of scenarios, but warned the default cannot address severe skewness or small samples.




Let’s compare the distributions of original and imputed data using a some useful plots.
First of all we can use a scatterplot and plot Ozone against all the other variables
Let's first plot the variables for which we have few missing values
```{r distr_orig_pred}

xyplot(igf,IFNy ~ SOCS1 + IRGM1 + MUC2, pch=18,cex=1)
```


What we would like to see is that the shape of the magenta points (imputed) matches the shape of the blue ones (observed). The matching shape tells us that the imputed values are indeed “plausible values”.

Now let's plot the variables with many missing data points.


```{r distr_orig_pred2}

xyplot(igf,IFNy ~ IL.10 + PRF1 + CASP1, pch=18,cex=1)
```



```{r densityplotfield}
densityplot(igf)
```

The density of the imputed data for each imputed dataset is showed in magenta while the density of the observed data is showed in blue. Again, under our previous assumptions we expect the distributions to be similar.

Another useful visual take on the distributions can be obtained using the stripplot() function that shows the distributions of the variables as individual points


```{r strirrplot}
stripplot(igf, pch = 20, cex = 1.2)
```

## Applying the model for predicting weight loss to our imputed data set

Start by making the predictions for the field data. 


```{r }
# Start by selecting the columns that appear in both the training data set and the 
# field data set
completeField <- completeField %>%
  dplyr::select(intersect(colnames(completeField), colnames(train.data)))

set.seed(540)

#The predict() function in R is used to predict the values based on the input data.
predictions_field <- predict(model, completeField)

# assign test.data to a new object, so that we can make changes
result_field <- completeField

#add the new variable of predictions to the result object
result_field <- cbind(result_field, predictions_field)

#add the results to a data frame containing test data and the prediction
f <- f %>% 
  dplyr::select(-intersect(colnames(result_field), colnames(f)))

result_field <- cbind(f, result_field)
```


## It is time to apply the package of Alice Balard et al. on our predictions!


Let's see if we indeed have differences across the hybrid index with our predicted 
weight loss. 

```{r, warning=FALSE, echo=FALSE, message=FALSE}
require(devtools)

devtools::install_github("alicebalard/parasiteLoad@v2.0", force = TRUE)

#force = TRUE)

library(parasiteLoad)
```

## Check the distribution 

```{r}
result_field %>% ggplot(aes(x = predictions_field)) +
  geom_histogram(binwidth = 1.5)



```

```{r}
result_field %>%
    ggplot(aes(x = HI , y = predictions_field , color = Sex)) +
    geom_smooth() +
    geom_point()


result_field %>%
    ggplot(aes(x = Body_Length , y = predictions_field , color = Sex)) +
    geom_smooth() +
    geom_point()
```

Nice to see that they are normally distributed. 


Fitting distributions??

Ratios / Percentages are not normally distributed. Weibull is a good distributions. 

Alice used weibull for the qpcr data. (paper) 

```{r}
library(fitdistrplus)
library(logspline)

result_field <- result_field %>%
dplyr::mutate(WL = predictions_field)

x <- result_field$WL

descdist(data = x, discrete = FALSE)
descdist(data = x, discrete = FALSE, #data is continuous
         boot = 1000)


```

Test for binomial distribution

```{r}
set.seed(10)
n = 25
size = 27
prob = .4
data = rbinom(x, size = size, prob = prob)
fit = fitdist(data = data, dist="binom", 
                   fix.arg=list(size = size), 
                   start=list(prob = 0.1))

summary(fit)


plot(fit)
```


```{r}
normal_ <- fitdist(x, "norm")
weibull_ <- fitdist(x, "weibull")
gamma_ <- fitdist(x, "gamma")
```
```{r}
library(fitdistrplus) # evaluate distribution

# Define function to be used to test, get the log lik and aic
tryDistrib <- function(x, distrib){
  # deals with fitdistr error:
  fit <- tryCatch(MASS::fitdistr(x, distrib), error=function(err) "fit failed")
  return(list(fit = fit,
              loglik = tryCatch(fit$loglik, error=function(err) "no loglik computed"), 
              AIC = tryCatch(fit$aic, error=function(err) "no aic computed")))
}



findGoodDist <- function(x, distribs, distribs2){
  l =lapply(distribs, function(i) tryDistrib(x, i))
  names(l) <- distribs
  print(l)
  listDistr <- lapply(distribs2, function(i){
    if (i %in% "t"){
      fitdistrplus::fitdist(x, i, start = list(df =2))
    } else {
      fitdistrplus::fitdist(x,i)
    }}
  ) 
  par(mfrow=c(2,2))
  denscomp(listDistr, legendtext=distribs2)
  cdfcomp(listDistr, legendtext=distribs2)
  qqcomp(listDistr, legendtext=distribs2)
  ppcomp(listDistr, legendtext=distribs2)
  par(mfrow=c(1,1))
}
```

```{r}
tryDistrib(x, "normal")

```

```{r}
tryDistrib(x, "binomial")
```

```{r}
tryDistrib(x, "student")
```


```{r}
tryDistrib(x, "weibull")
```

```{r , warnings = FALSE, message = FALSE}
tryDistrib(x, "weibullshifted")
```
```{r}
findGoodDist(x, "normal", "weibull")
```

```{r normal}
plot(normal_)
summary(normal_)
```
```{r gamma_}
plot(gamma_)
summary(gamma_)
```

```{r weibull_}
plot(weibull_)
summary(weibull_)
```

 ### Is alpha significant for each hypothesis?

H0: the expected load for the subspecies and between 2 groups is the same

H1: the mean load across 2 groups is the same, but can differ across subspecies

H2: the mean load across subspecies is the same, but can differ between the 2 groups

H3: the mean load can differ both across subspecies and between 2 groups


```{r}

result_field$Sex <- as.factor(result_field$Sex)

result_field <- result_field %>%
    drop_na(HI)

parasiteLoad::getParamBounds("weibull", data = result_field, response = "WL")


speparam <- c(L1start = 10,
                     L1LB = 1e-9,
                     L1UB = 20,
                     L2start = 10,
                     L2LB = 1e-9,
                     L2UB = 20,
                     alphaStart = 0, alphaLB = -5, alphaUB = 5,
                     myshapeStart = 1, myshapeLB = 1e-9, myshapeUB = 5)

##All
fitWL_Sex <- parasiteLoad::analyse(data = result_field,
                        response = "WL",
                        model = "weibull",
                        group = "Sex")

fitWL_Sex

plot_WL_Sex<- bananaPlot(mod = fitWL_Sex$H3,
             data = result_field,
             response = "WL",
             group = "Sex") +
    scale_fill_manual(values = c("blueviolet", "chartreuse2")) +
  scale_color_manual(values = c("blueviolet", "chartreuse2")) +
  theme_bw() + 
    xlab(label = "Hybrid Index") +
    ylab(label = "Weight loss (Health impact)")
 
    
    
plot_WL_Sex

HIgradientBar <- ggplot(data.frame(hi = seq(0,1,0.0001)),
                        aes(x=hi, y=1, fill = hi)) +
  geom_tile() +
  theme_void() +
  scale_fill_gradient(low = "blue", high = "red")  + 
  scale_x_continuous(expand=c(.01,0)) + 
  scale_y_continuous(expand=c(0,0)) +
  theme(legend.position = 'none')

plot_grid(plot_WL_Sex + theme(legend.position = "none") , HIgradientBar,  
                            nrow = 2, 
                            rel_heights = c(1.5, 1/8),
          align = "v")
     
```


## Summary stats for the field 

Can we test the hybrid index, WL and the infection ? 

```{r}
result_field %>%
    dplyr::group_by(MC.Eimeria) %>%
    summarize(length(Mouse_ID))
```


```{r}
result_field %>%
    dplyr::group_by(eimeriaSpecies) %>%
    summarize(length(Mouse_ID))
```

## Reproducing for melting curve


```{r}

result_field_mc <- result_field %>% 
    drop_na("MC.Eimeria")

parasiteLoad::getParamBounds("weibull", data = result_field_mc, response = "WL")


speparam <- c(L1start = 10,
                     L1LB = 1e-9,
                     L1UB = 20,
                     L2start = 10,
                     L2LB = 1e-9,
                     L2UB = 20,
                     alphaStart = 0, alphaLB = -5, alphaUB = 5,
                     myshapeStart = 1, myshapeLB = 1e-9, myshapeUB = 5)


result_field_mc <- result_field_mc %>%
    dplyr::mutate(Eimeria = case_when(
        MC.Eimeria == "TRUE" ~ "positive",
        MC.Eimeria == "FALSE" ~ "negative",
        TRUE ~ ""
    ))

result_field_mc$Eimeria <- as.factor(result_field_mc$Eimeria)


##All
fitWL_Eimeria <- parasiteLoad::analyse(data = result_field_mc,
                        response = "WL",
                        model = "weibull",
                        group = "Eimeria")
fitWL_Eimeria

plot_WL_Eimeria <- bananaPlot(mod = fitWL_Eimeria$H0,
             data = result_field_mc,
             response = "WL",
             group = "Eimeria") +
  scale_fill_manual(values = c("blue", "red")) +
  scale_color_manual(values = c("blue", "red")) +
  theme_bw()

plot_WL_Eimeria

```

## Applying the classification model on the field data



Let's see how well our predictions work!


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_melting_field <- predict(model_melting, result_field_mc)
# assign test.data to a new object, so that we can make changes


result_melting_field <- result_field_mc
#add the new variable of predictions to the result object
result_melting_field <- cbind(result_melting_field, predictions_melting_field)


#turn the variable of melting curve into a factor so that you can compare to the predictions
result_melting_field$MC.Eimeria <- as.factor(as.character(result_melting_field$MC.Eimeria))

```





```{r }

conf_matrix_melting_field <- confusionMatrix(result_melting_field$predictions_melting_field, reference = result_melting_field$MC.Eimeria)

print(conf_matrix_melting_field)
conf_matrix_melting_field$table

plt <- as.data.frame(conf_matrix_melting_field$table)

plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))
ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 
```

## Test the other model for parasite species
## Making predictions


```{r }
result_field_par <- result_field %>%
    drop_na(eimeriaSpecies) %>%
    mutate(Parasite_challenge = case_when(
        eimeriaSpecies == "Negative" ~ "uninfected",
        eimeriaSpecies == "E_ferrisi" ~ "E_ferrisi",
        eimeriaSpecies == "E_falciformis" ~ "E_falciformis",
        TRUE ~ ""
    ))  %>% 
    drop_na(Parasite_challenge)

#The predict() function in R is used to predict the values based on the input data.
predictions_parasite_field <- predict(model_Parasite, result_field_par)


#add the new variable of predictions to the result object
result_field_par <- cbind(result_field_par, predictions_parasite_field)


```




## Visualizations



```{r }
result_field_par$Parasite_challenge <- as.factor(result_field_par$Parasite_challenge)

conf_matrix_parasite <- confusionMatrix(result_field_par$predictions_parasite_field, reference = result_field_par$Parasite_challenge)



print(conf_matrix_parasite)

conf_matrix_parasite$table

plt <- as.data.frame(conf_matrix_parasite$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```
## Next steps

Question the removal of CXCL3, maybe it exists in the wild and we need to rename
How to deal with the delta ct?

#what about instead of classifying testing with random forest for infection intensity?




##########################################################


### Let's test if we can predict infection intensity according to gene expression
## Splitting data into training and testing sets 
Splitting between training and testing:
- Assess model performance on unseen data
- Avoid over-fitting 



```{r }
#select the relevant columns:
g.imputed <- g.imputed_full %>%
    dplyr::select(c(delta, all_of(Genes))) %>%
    drop_na(delta)

g.imputed <- g.imputed %>%
    rename(CXCR3 = CXCR3_bio)

# split data into training and test

set.seed(123) # this will help us reproduce this random assignment

# in this way we can pick the random numbers

training.samples <- g.imputed$delta%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return

train.data <- g.imputed[training.samples, ] #include all the randomly selected rows
test.data <- g.imputed[-training.samples, ] 


```



## Building the model

```{r }
#train the model
model_delta <- randomForest(delta ~., data = train.data, proximity = TRUE,
                      ntree = 1000) # number of trees
                      

print(model_delta)
```

Plotting the model will illustrate the error rate as we average across more trees and shows that our error rate stabalizes with around 200 trees.



```{r}
plot(model_delta)
```


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions <- predict(model_delta, test.data)

# assign test.data to a new object, so that we can make changes
result <- test.data

#add the new variable of predictions to the result object
result <- cbind(result, predictions)


Parasite_challenge <- g.imputed_full %>% slice(as.numeric(row.names(result)))

Parasite_challenge <- Parasite_challenge %>% 
    dplyr::select(Parasite_challenge)

result <- cbind(result, Parasite_challenge)



```




## Visualizations



```{r }
result %>%
  ggplot() +
  geom_point(aes(x = predictions, y = delta, color = Parasite_challenge)) +
  geom_abline() +
  labs(x = "Predictions: Infection intensity", y = "Infection intensity") +
    theme_bw()

```

```{r}
cor(result$predictions, result$delta)
```

  Okay! Now let's test it on the field
  
  ## Applying the model for predicting weight loss to our imputed data set

Start by making the predictions for the field data. 


```{r }
# Start by selecting the columns that appear in both the training data set and the 
# field data set

#Now we can get back the completed dataset using the complete()
completeField <- complete(igf, 1)

completeField <- completeField %>%
  dplyr::select(intersect(colnames(completeField), colnames(train.data)))

set.seed(333)

#The predict() function in R is used to predict the values based on the input data.
predictions_field <- predict(model_delta, completeField)

# assign test.data to a new object, so that we can make changes
result_field <- completeField

#add the new variable of predictions to the result object
result_field <- cbind(result_field, predictions_field)

#add the results to a data frame containing test data and the prediction
delta_field <- f %>% dplyr::select(delta_ct_cewe_MminusE)

result_field <- cbind(delta_field, result_field)

result_field <- result_field %>%
    drop_na(delta_ct_cewe_MminusE)

# let's see wht the ratio between acutal data and predictions
result_field <- result_field %>% 
    mutate(ratio =  delta_ct_cewe_MminusE / predictions_field)

summary(result_field$ratio)

result_field %>% 
    ggplot(aes(x = ratio)) +
    geom_histogram()

result_field2 <- result_field %>% 
    dplyr::filter(!ratio >= 6) 

result_field2 %>% 
    ggplot(aes(x = ratio)) +
    geom_histogram()


summary(result_field2$ratio)
```



## Visualizations



```{r }


result_field   %>%
  ggplot(aes(x = predictions_field, y = delta_ct_cewe_MminusE)) +
  geom_point() +
  geom_abline() +
  labs(x = "Predictions: Infection intensity", y = "Observed: Infection intensity") +
    theme_bw()
  
```


```{r}
cor(result_field$predictions_field, result_field$delta_ct_cewe_MminusE)
```
# let's try using multiplying the predictions by the ratio of 2.5

```{r}
# adding the "normalization" 
result_field2 <- result_field2 %>%
    mutate(predictions_norm = predictions_field * 2.493)

result_field2 <- result_field2  %>%
    dplyr::select(c(delta_ct_cewe_MminusE, predictions_field, predictions_norm, ratio))

cor(result_field2$predictions_norm, result_field2$delta_ct_cewe_MminusE)

cor.test(result_field2$predictions_norm, result_field2$delta_ct_cewe_MminusE,
                    method = "pearson")
result_field2   %>%
  ggplot(aes(x = predictions_norm, y = delta_ct_cewe_MminusE)) +
  geom_point() +
  labs(x = "Predictions: Infection intensity", y = "Observed: Infection intensity") +
    theme_bw()
```



