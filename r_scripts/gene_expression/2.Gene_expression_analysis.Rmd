---
title: "2.Gene expression anaylsis: Creating random forest models on lab data"
author: "Fay Webster"
date: '2022-05-27'
output:
  html_document: 
  theme: journal
  toc: true
  toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  warning = FALSE)
```


# Aim: 
- Predicting health impact of infections utilizing immune parameters as predictors 
- Predicted variable: WL as a proxy of health 
- To do that we are using immune data from experimental lab infections. 
- We are training random forest models on the immune data from experimental lab infections 
- And we test them on the field.
- We then compare the differences in the predicted health impact among non-hybrid and hybrid mice. 


In this document I am preparing the models using the lab data only. 

# Install necessary libraries:
```{r libraries, message = FALSE, warnings = FALSE}
#install.packages("optimx", version = "2021-10.12") # this package is required for 
#the parasite load package to work
library(tidyverse)
library(tidyr)
library(dplyr)
library(cowplot)
library(randomForest)
library(ggplot2)
library(caret)
library(VIM) # visualizing missing data
library(mice) # imputing missing data without predictors
library(ggpubr)
library(optimx)
```


# Laboratory data 

## Importing the data

We start with the data from experimental lab infections. 

```{r import_data,  message = FALSE, warnings = FALSE }
# Here we import the cleaned data set from the previous script derived from the 
# data set challenge infections 
g <- read.csv("https://raw.githubusercontent.com/fayweb/Eimeria_mouse_immunity/main/output_data/gene_expression/data_products/clean_gene_expression.csv")


# vectors for selecting gene columns
Genes <- c("IFNy", "CXCR3_bio", "IL.6", "IL.10", "IL.13", "IL.10", "IL.13", "IL1RN", 
           "CASP1", "CXCL9", "IDO1", "IRGM1", "MPO", "MUC2", "MUC5AC", "MYD88", 
           "NCR1", "PRF1", "RETNLB", "SOCS1", "TICAM1", "TNF")

```



## Data cleaning / preparation

```{r cleaning}
# we need to change the  in challenge infections to a factor
g$Parasite_challenge <- as.factor(g$Parasite_challenge)
g$Eim_MC <- as.factor(g$Eim_MC)

# Here I create a new column, where we get the actual infection status
# According to the melting curve for eimeria 
g <- g %>%
  dplyr::mutate(current_infection = case_when(
    Parasite_challenge == "E_ferrisi" & Eim_MC == "TRUE" ~ "E_ferrisi",
    Parasite_challenge == "E_ferrisi" & Eim_MC == "FALSE" ~ "uninfected",
    Parasite_challenge == "E_falciformis" & Eim_MC == "TRUE" ~ "E_falciformis",
    Parasite_challenge == "E_falciformis" & Eim_MC == "FALSE" ~ "uninfected",
    Parasite_challenge == "uninfected" & Eim_MC == "TRUE" ~ "infected_eimeria",
    Parasite_challenge == "uninfected" & Eim_MC == "FALSE" ~ "uninfected",
    TRUE ~ ""
  ))


# create variable maximum weight loss instead of maximum relative weight loss
g <- g %>% dplyr::mutate(max_WL = 100 - max_WL)


```

# Imputation of missing data 


## Imputing missing data + cleaning

Here, I am using a function from the random forest package, rfImpute which utilizes 
random forests to impute missing data in the other variables. 

The variables used for imputing mainly the immune gene expression are the current 
infection, the state of Eimeria infection, oocysts and the non-missing genes.


```{r imputing}
#Start by selecting only the genes and the maximum weight loss for each mouse
# Apparently the relative end weight doesn't work so well for predictions

g.1 <- g %>% dplyr::select(c(all_of(Genes), max_WL,
                             primary_infection, challenge_infection, mouse_strain,
                             Parasite_primary, Parasite_challenge, max_OOC, Eim_MC,  delta,
                             Parasite_primary, Parasite_challenge, OPG_O))

sapply(g.1, function(x) sum(is.na(x)))
g.1$max_OOC[is.infinite(g.1$max_OOC)] <- NA  


g.1  <- g.1 %>% mutate_if(is.character, as.factor)
g.1  <- g.1 %>% mutate_if(is.integer, as.numeric)


# to get reproducible results we use a seed
set.seed(42)

# We want the maximum weight loss to be predicted by the data ina ll of the other columns

# iter = how many random forests are needed, in theory 6 are enough
g.imputed <- rfImpute(max_WL ~ ., data = g.1, iter = 6)



g_minus <- g %>% 
  dplyr::select(-c(max_WL, primary_infection, challenge_infection, 
                  mouse_strain, Parasite_primary, Parasite_challenge, max_OOC, 
                  Eim_MC, delta, Parasite_primary, Parasite_challenge, OPG_O, all_of(Genes)))

#full data set containing the imputed gene expression data
g.imputed <- cbind(g_minus, g.imputed)

```


How many mice are in the infection planning?
```{r infection_plan}
g.imputed %>% 
  filter(infection == "challenge") %>%
  group_by(Parasite_challenge) %>%
  summarize(length(EH_ID))
  
``` 
How many mice are indeed infected?

```{r infected}
g.imputed %>% 
  filter(infection == "challenge") %>%
  group_by(current_infection) %>%
  summarize(length(EH_ID))
  
```
I guess mice got mixed up here?

## Splitting data into training and testing sets 
Splitting between training and testing:
- Assess model performance on unseen data
- Avoid over-fitting 


# Random forest for predicting percentage of maximum weight loss

## Dividing data into training and testing 

```{r Diving_testing_training}

Genes <- c("IFNy",  "IL.6", "IL.10", "IL.13", "IL.10", "IL.13", "IL1RN", 
           "CASP1", "CXCL9", "IDO1", "IRGM1", "MPO", "MUC2", "MUC5AC", "MYD88", 
           "NCR1", "PRF1", "RETNLB", "SOCS1", "TICAM1", "TNF")

g.imputed_full <- g.imputed

#select the relevant columns:
g.imputed <- g.imputed %>%
  dplyr::select(c(max_WL, all_of(Genes))) 

# split data into training and test

set.seed(123) # this will help us reproduce this random assignment

# in this way we can pick the random numbers

training.samples <- g.imputed$max_WL%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return

train.data <- g.imputed[training.samples, ] #include all the randomly selected rows
test.data <- g.imputed[-training.samples, ] 


```



## Building the model

```{r  predicting_weight_loss_model}
#train the model
weight_loss_predict <- randomForest(max_WL ~., data = train.data, proximity = TRUE,
                      ntree = 1000) # number of trees
                      

print(weight_loss_predict)
```

Plotting the weight_loss_predict will illustrate the error rate as we average across more trees and shows that our error rate stabalizes with around 200 trees.


## Model - quality testing

```{r}
plot(weight_loss_predict)
```
The plotted error rate above is based on the OOB sample error and can be accessed directly at m1$mse. Thus, we can find which number of trees providing the lowest error rate, which is 257 trees providing an weight error of 5.024738.

```{r}
# number of trees with lowest MSE
which.min(weight_loss_predict$mse)
## [1] 257

# RMSE of this optimal random forest
sqrt(weight_loss_predict$mse[which.min(weight_loss_predict$mse)])
## [1] 5.024738
```

### https://uc-r.github.io/s
RandomForest also allows us to use a validation set to measure predictive accuracy if we did not want to use the OOB samples. 



Tutorial: https://hackernoon.com/random-forest-regression-in-r-code-and-interpretation
Random forest regression in R provides two outputs: decrease in mean square error (MSE) and node purity. Prediction error described as MSE is based on permuting out-of-bag sections of the data per individual tree and predictor, and the errors are then averaged. In the regression context, Node purity is the total decrease in residual sum of squares when splitting on a variable averaged over all trees (i.e. how well a predictor decreases variance). MSE is a more reliable measure of variable importance. If the two importance metrics show different results, listen to MSE. If all of your predictors are numerical, then it shouldnâ€™t be too much of an issue


Mean Decrease Gini (IncNodePurity) - This is a measure of variable importance based on the Gini impurity index used for the calculating the splits in trees.

Improving Your Model
Your model depends on the quality of your dataset and the type of Machine Learning algorithm used. Therefore, to improve the accuracy of your model, you should:

Check what attributes affect our model the most and what variables to leave out in future analysis
Find out what other attributes affect a person's wage; we can use as predictors in future analysis
Tweak the algorithm (e.g. change the ntree value)
Use a different machine learning algorithm
If any of these reduces the RMSE significantly, you have succeeded in improving your model!

```{r include = FALSE, message = FALSE, echo = FALSE}
### Visualize variable importance ----------------------------------------------

#Call importance() function on the model model to check how the attributes used as predictors affect our weight_loss_predict
importance(weight_loss_predict)

weight_loss_predict$mse
## S3 method for class 'randomForest'
plot(weight_loss_predict, type = "l", main=deparse(substitute(x)))

varImpPlot(weight_loss_predict)

# Get variable importance from the weight_loss_predict fit
ImpData <- as.data.frame(importance(weight_loss_predict))
ImpData$Var.Names <- row.names(ImpData)

#ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
 # geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
  #geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
  #theme_light() +
  #coord_flip() +
  #theme(
   ## legend.position="bottom",
    #panel.grid.major.y = element_blank(),
    #panel.border = element_blank(),
    #axis.ticks.y = element_blank()
  #)
```



# Application of weight_loss_predict
## Using the testing data

Let's now make some predictions using our test data.


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions <- predict(weight_loss_predict, test.data)

# assign test.data to a new object, so that we can make changes
result <- test.data

#add the new variable of predictions to the result object
result <- cbind(result, predictions)

#add the results to a data frame containing test data and the prediction
result <- cbind(g[row.names(result), ], predictions)

cor(result$max_WL, result$predictions, method = c("pearson", "kendall", "spearman"))
```



## Visualizing the predictions



```{r predictions_weight_loss_predict_wL }
# trying to find a way to represent the delta ct for the negative ones
# please find a better way to do this
result <- result %>% 
    dplyr::mutate(Infection_intensity = case_when(
       Parasite_challenge == "uninfected" ~ -9,
       TRUE ~ delta
    ))

result   %>%
  ggplot() +
  geom_point(aes(x = predictions, y = max_WL, color = Parasite_challenge, size = Infection_intensity)) +
  labs(x = "Predictions: Maximum weight loss", y = "Observed: Maximum weight loss") +
    theme_bw()
  
```


# Validation of the model. Using the same method to predict either Melting curve or infecting parasite

As a second part I am using the same method to predict either infection wit
Eimeria in general or the species of eimeria. 

##  Predicting eimeria species



### Predicing parasite: splliting into training and testing

```{r }

g.imputed_full$Parasite_challenge <- as.factor(g.imputed_full$Parasite_challenge)

#select the relevant columns:
g.imputed_parasite <- g.imputed_full %>%
  dplyr::select(c(Parasite_challenge, all_of(Genes)))

# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_parasite <- g.imputed_parasite$Parasite_challenge%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_parasite <- g.imputed_parasite[training.samples, ] #include all the randomly selected rows
test.data_parasite <- g.imputed_parasite[-training.samples, ] 


```

### Building the model_Parasite

```{r }
#train the model
model_Parasite <- randomForest(Parasite_challenge ~., data = train.data_parasite, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_Parasite)
```
OOB = 46.43, this means that only 53 % of our predictions are accurate



```{r}
plot(model_Parasite)
```

### Testing the model: Predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_parasite <- predict(model_Parasite, test.data_parasite)
# assign test.data to a new object, so that we can make changes
result_parasite <- test.data_parasite
#add the new variable of predictions to the result object
result_parasite <- cbind(result_parasite, predictions_parasite)
#add the results to a data frame containing test data and the prediction
result_parasite <- cbind(g[row.names(result_parasite), ], predictions_parasite)
```


## Visualizations



```{r }

conf_matrix_parasite <- confusionMatrix(result_parasite$predictions_parasite, reference = result_parasite$Parasite_challenge)

print(conf_matrix_parasite)

conf_matrix_parasite$table

plt <- as.data.frame(conf_matrix_parasite$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```


## Now split the data again into training and testing
```{r splitting_data}

g.imputed_parasite$Parasite_challenge <- as.factor(g.imputed_parasite$Parasite_challenge)

#select the relevant columns:
g.imputed_parasite <- g.imputed_parasite %>%
  dplyr::select(c(Parasite_challenge, Eim_MC, all_of(Genes)))

# to use in the next model
parasite_data <- g.imputed_parasite

g.imputed_parasite <- g.imputed_parasite %>% 
  dplyr::select(-Eim_MC)

# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_parasite <- g.imputed_parasite$Parasite_challenge%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_parasite <- g.imputed_parasite[training.samples, ] #include all the randomly selected rows
test.data_parasite <- g.imputed_parasite[-training.samples, ] 
```

## Building the model

```{r }
#train the model
model_Parasite <- randomForest(Parasite_challenge ~., data = train.data_parasite, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_Parasite)
```
OOB = 46.43, this means that only 53 % of our predictions are accurate



```{r}
plot(model_Parasite)
```

## Test the model


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_parasite <- predict(model_Parasite, test.data_parasite)
# assign test.data to a new object, so that we can make changes
result_parasite <- test.data_parasite
#add the new variable of predictions to the result object
result_parasite <- cbind(result_parasite, predictions_parasite)
#add the results to a data frame containing test data and the prediction
result_parasite <- cbind(g[row.names(result_parasite), ], predictions_parasite)
```




## Visualizations



```{r }

conf_matrix_parasite <- confusionMatrix(result_parasite$predictions_parasite, reference = result_parasite$Parasite_challenge)

print(conf_matrix_parasite)

conf_matrix_parasite$table

plt <- as.data.frame(conf_matrix_parasite$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```


```{r}
train.data_parasite %>% 
  group_by(Parasite_challenge) %>%
  summarize(length(Parasite_challenge))
```

### Repeat the previous model, this time testing for
infected with Eimeria or not. ###

```{r melting-curve - model}

# to use in the next model
parasite_data <- parasite_data %>%
  dplyr::select(-Parasite_challenge)




# split data into training and test
set.seed(123) # this will help us reproduce this random assignment
# in this way we can pick the random numbers
training.samples_melting <- parasite_data$Eim_MC%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return
train.data_melting <- parasite_data[training.samples, ] #include all the randomly selected rows
test.data_melting <- parasite_data[-training.samples, ] 
```



## Building the model

```{r }
#train the model
model_melting <- randomForest(Eim_MC ~., data = train.data_melting, proximity = TRUE,
                      ntree = 1500) # number of trees
                      
print(model_melting)
```

## Test the model


## Making predictions


```{r }
#The predict() function in R is used to predict the values based on the input data.
predictions_melting <- predict(model_melting, test.data_melting)


# assign test.data to a new object, so that we can make changes
result_melting <- test.data_melting
#add the new variable of predictions to the result object
result_melting <- cbind(result_melting, predictions_melting)
#add the results to a data frame containing test data and the prediction
result_melting <- cbind(g[row.names(result_melting), ], predictions_melting)
```





```{r }

conf_matrix_melting <- confusionMatrix(result_melting$predictions_melting, reference = result_melting$Eim_MC)

print(conf_matrix_melting)

conf_matrix_melting$table

plt <- as.data.frame(conf_matrix_melting$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(x = Prediction, y =  Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="forestgreen") +
        labs(x = "Predictions",y = "Reference") 

```
