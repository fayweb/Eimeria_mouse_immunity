---
title: "2.Regularization_facs"
author: "Fay"
date: '2022-05-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Load the libraries.

```{r}
library(tidyr)
library(dplyr)
library(caret) #splitting data

```


```{r reading the data}
# Here is the data file containing the cleaned facs data (non-imputed)
f <- read.csv("output_data/facs/data_products/FACS_clean.csv")

#and here is the file with the imputed data 
f_imp <- read.csv("output_data/facs/data_products/imputed_facs_data.csv")

## vectors for selecting columns
CellCount.cols <- c("CD4", "Treg", "Div_Treg", "Treg17", "Th1", 
                    "Div_Th1", "Th17", "Div_Th17", "CD8", "Act_CD8", 
                    "Div_Act_CD8", "IFNy_CD4", "IFNy_CD8","Treg_prop", 
                    "IL17A_CD4")  

```


## Preparing the data for regularization

```{r summ_stats}
#how many mice in the primary infections
f %>%  
  as.tibble() %>%
  group_by(Parasite_primary) %>%
  summarise(length(EH_ID))

#how may mice in the challenge
f %>%  
  as.tibble() %>%
  group_by(Parasite_challenge) %>%
  summarise(length(EH_ID))
```
```{r}
f %>% 
  ggplot(aes(x = max_WL)) +
  geom_histogram()
```
#### Splitting data into training and testing sets 
Splitting between training and testing:
- Assess model performance on unseen data
- Avoid over-fitting 


```{r}
facs <- f_imp %>% 
  dplyr::select(c(all_of(CellCount.cols), Parasite_challenge, max_WL))

# split data into training and test

set.seed(123) # this will help us reproduce this random assignment

# in this way we can pick the random numbers

training.samples <- f_imp$max_WL%>%
  createDataPartition(p = .7, # this is the partiicition! In this case 0.7 = training data and 0.3 = testing
                      list = FALSE) # we don't want to get a list in return

train.data <- f_imp[training.samples, ] #include all the randomly selected rows
test.data <- f_imp[-training.samples, ] 




```


